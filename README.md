[![LICENSE](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/sebasmos/DeepCuriosity/blob/main/LICENSE)

# ğŸ§  DeepCuriosity

**Simple PyTorch implementation of PPO and Intrinsic Curiosity Module (ICM)** for fast training and visualization in [MuJoCo](https://github.com/google-deepmind/mujoco) environments such as `Swimmer-v4`.

---

## ğŸ”§ Whatâ€™s Inside

- âœ… **PPO baseline** (MLP actor-critic)
- ğŸ” **PPO + ICM** (intrinsic curiosity)
- ğŸ“Š CSV logs & reward plots
- ğŸï¸ Automatic episode-video rendering
- ğŸ—‚ï¸ Clean directory layout â†’ everything lands under `data/`

---

## ğŸ“¦ Installation

```bash
# create and activate environment
conda create -n ppo_icm python=3.11 -y
conda activate ppo_icm

# install dependencies
pip install -r requirements.txt
```

*`requirements.txt` already pins the exact versions we tested (Gymnasium 1.1.1, Torch 2.5.1, NumPy 2.2.5, â€¦).*  
*If you prefer a one-liner:*
```bash
pip install torch==2.5.1 gymnasium==1.1.1 mujoco glfw \
            matplotlib==3.10.1 imageio==2.33.1 imageio[ffmpeg] \
            hydra-core==1.3.2 pyyaml pandas==2.2.3 numpy==2.2.5 ipython==8.12.3
```

---

## ğŸš€ How to Run

### 1. Train PPO baseline
```bash
python baseline.py                # uses configs/config.yaml
```

### 2. Train PPO + ICM (curiosity)
```bash
python curiosity.py               # same config file
```

*(Both scripts rely on Hydra; you can override parameters on the CLI, e.g. `python baseline.py steps=1_000_000`)*

---

## ğŸ“ˆ Visualise Results

Open **`plot.ipynb`** and run the cells to

- plot reward curves for both agents,
- compare moving averages,
- embed rendered videos.

---

## ğŸ—‚ï¸ Project & Output Structure

```bash
RL/
â”œâ”€â”€ baseline.py          # PPO training script
â”œâ”€â”€ curiosity.py         # PPO + ICM training script
â”œâ”€â”€ utils.py             # logging, plotting, video helpers
â”œâ”€â”€ models.py            # agent & ICM networks
â”œâ”€â”€ buffer.py            # PPO buffer with GAE
â”œâ”€â”€ plot.ipynb           # notebook for analysis/visuals
â”œâ”€â”€ configs/config.yaml  # shared Hydra config
â””â”€â”€ data/                # â† all artefacts saved here
    â”œâ”€â”€ raw_pytorch/     #   baseline runs
    â”‚   â””â”€â”€ Swimmer-v4/
    â”‚       â””â”€â”€ mlp_256_raw_pytorch_<timestamp>/
    â”‚           â”œâ”€â”€ checkpoints/   # model_update_<n>_steps_<k>.pt
    â”‚           â”œâ”€â”€ logs/          # metrics.csv per update
    â”‚           â”œâ”€â”€ episode_rewards.npy
    â”‚           â””â”€â”€ video_*.mp4    # optional roll-out videos
    â””â”€â”€ ppo_icm/        #   curiosity runs
        â””â”€â”€ Swimmer-v4/
            â””â”€â”€ mlp_256_icm_pytorch_<timestamp>/
                â”œâ”€â”€ checkpoints/
                â”œâ”€â”€ logs/
                â”œâ”€â”€ episode_rewards.npy
                â””â”€â”€ video_*.mp4
```

---

## ğŸ¤ Contribute / Contact

Feel free to **fork, open issues or send PRs**.  
Questions or ideas? â†’ [@sebasmos](https://github.com/sebasmos)

---

## âš¡ To-Do / Ideas

- [ ] Extra curiosity bonuses (RND, RIDE, Disagreement)
- [ ] Support more MuJoCo tasks (Hopper, HalfCheetah, Antâ€¦)
- [ ] TensorBoard & Weights-and-Biases logging
- [ ] CLI policy-evaluation script
- [ ] dm_control wrapper to play with custom joint counts

---

## ğŸ“š References

* **Curiosity-Driven Exploration** â€“ <https://arxiv.org/abs/2109.08603>  
* **Artificial Curiosity since 1990** â€“ <https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html>
